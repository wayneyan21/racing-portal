# -*- coding: utf-8 -*-
"""
HKJC RaceCard å…¨æ—¥æ’ä½è¡¨ï¼ˆSelenium æ“´å……ç‰ˆï¼‰
- è‡ªå‹•åµæ¸¬è³½æ—¥/å ´åœ°
- å‹¾é¸ çˆ¶ç³»/æ¯ç³»/é€²å£é¡åˆ¥ â†’ é‡æ–°æ•´ç†
- è§£æã€Œè³½äº‹å±¤(meta)ã€ï¼‹ã€Œé¦¬åŒ¹å±¤(entries)ã€
- ç”¢ç”Ÿé–‹è³½æ™‚é–“ï¼ˆLocal/HKT/UTCï¼‰
- æ”¯æ´ï¼šCSV è¼¸å‡ºã€MySQL å…¥åº«ï¼ˆracecard_races / racecard_entriesï¼‰

ç”¨æ³•ï¼š
  python crawl_racecard_simple.py --date 2025-10-22 --course HV --mysql \
    --mysql-host 127.0.0.1 --mysql-user root --mysql-pass Aa40404040 --mysql-db hkjc
"""
import re
import csv
import json
import time
import argparse
import datetime as _dt
import os

# å¦‚æœä½ æœ¬åœ°ç”¨ .envï¼Œå¯ä»¥è£ python-dotenvï¼š
#   pip install python-dotenv
try:
    from dotenv import load_dotenv
    load_dotenv()  # æœƒè‡ªå‹•è®€å°ˆæ¡ˆæ ¹ç›®éŒ„çš„ .envï¼ˆå¦‚æœæœ‰ï¼‰
except ImportError:
    # æ²’æœ‰å®‰è£ python-dotenv éƒ½å†‡å•é¡Œï¼Œåœ¨ Render æœƒç›´æ¥ç”¨ç’°å¢ƒè®Šæ•¸
    pass

from typing import List, Dict, Any, Tuple, Optional

from bs4 import BeautifulSoup
from zoneinfo import ZoneInfo  # Python 3.9+
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# ---------- ç¶²å€èˆ‡è·¯å¾‘ ----------
BASE = "https://racing.hkjc.com"
DEFAULT_RC = f"{BASE}/racing/information/Chinese/racing/RaceCard.aspx"
ZH_PATHS = [
    "/racing/information/Chinese/Racing/RaceCard.aspx",
    "/racing/information/Chinese/racing/RaceCard.aspx",
]
EN_PATHS = [
    "/racing/information/English/Racing/RaceCard.aspx",
    "/racing/information/English/racing/RaceCard.aspx",
]

# æ¬„ä½æ¬¡åºï¼ˆæœƒ map æˆå…·å dictï¼‰
WANTED_COLUMNS = [
    'é¦¬åŒ¹ç·¨è™Ÿ','6æ¬¡è¿‘ç¸¾','ç¶µè¡£','é¦¬å','çƒ™è™Ÿ','è² ç£…','é¨å¸«','æª”ä½','ç·´é¦¬å¸«',
    'è©•åˆ†','è©•åˆ†+/-','æ’ä½é«”é‡','æ’ä½é«”é‡+/-','é¦¬é½¡','åˆ†é½¡è®“ç£…','æ€§åˆ¥',
    'ä»Šå­£çé‡‘','å„ªå…ˆåƒè³½æ¬¡åº','ä¸Šè³½è·ä»Šæ—¥æ•¸','é…å‚™','é¦¬ä¸»','çˆ¶ç³»','æ¯ç³»','é€²å£é¡åˆ¥'
]

TIME_RE = re.compile(r"(?<!\d)(\d{1,2}:\d{2})(?!\d)")
SURF_WORDS = ["è‰åœ°","å…¨å¤©å€™","å…¨å¤©ä¾¯","AWT","æ³¥åœ°","All Weather","Turf"]
GOING_WORDS = ["å¥½åœ°","å¥½è‡³å¿«","å¿«åœ°","é»åœ°","è»Ÿåœ°","æ¿•è»Ÿ",
               "Good","Good to Firm","Firm","Yielding","Soft","Good to Yielding","Sloppy"]

# ---------- å…±ç”¨å·¥å…· ----------
def has_starter_table(html: str) -> bool:
    if not html: return False
    return bool(
        re.search(r"(é¦¬è™Ÿ|é¦¬å|æ’ä½é«”é‡|è² ç£…|ç·´é¦¬å¸«|é¨å¸«|å‡ºé¦¬è¡¨)", html) or
        re.search(r"(Horse No\.|Last 6 Runs|Horse Wt\.|Trainer|Jockey|Draw|Rtg)", html, re.I)
    )

def strip_html(s: str) -> str:
    s = re.sub(r"(?i)<br\s*/?>", " / ", s or "")
    s = re.sub(r"<[^>]+>", "", s)
    s = s.replace("&nbsp;"," ").replace("&amp;","&")
    s = re.sub(r"\s+", " ", s).strip()
    return s

def compact_html(s: str) -> str:
    return re.sub(r"\s{2,}", " ", re.sub(r"\r?\n+", " ", s or ""))

def pick_starter_table(compact: str) -> str:
    tables = re.findall(r"(?is)<table[^>]*>[\s\S]*?</table>", compact)
    if not tables: return ""
    best, best_score = "", -1
    for t in tables:
        score = 0
        if re.search(r'class="[^"]*\bf_fs12\b', t, re.I): score += 40
        if re.search(r'class="[^"]*\btable_bd\b', t, re.I): score += 30
        if re.search(r'(è¿‘ç¸¾|é¦¬å|æ’ä½é«”é‡|è² ç£…|ç·´é¦¬å¸«|é¨å¸«)', t): score += 25
        if re.search(r'(Horse No\.|Last 6 Runs|Horse Wt\.|Trainer|Jockey|Draw|Rtg)', t, re.I): score += 25
        trc = len(re.findall(r"(?i)<tr", t)); score += min(trc * 1.1, 40)
        if score > best_score: best_score, best = score, t
    return best

def index_by_header(headers: List[str]) -> Dict[str, int]:
    idx = {}
    aliases = {
        'é¦¬åŒ¹ç·¨è™Ÿ': ['åºè™Ÿ','é¦¬è™Ÿ','No','Number'],
        '6æ¬¡è¿‘ç¸¾': ['è¿‘ç¸¾','Last 6 Runs','Form'],
        'ç¶µè¡£': ['Silks','Colours','Colors','Jersey','çµ²è¡£','çµ²è¡«','çµ²è¤¸'],
        'é¦¬å': ['Horse','Horse Name','é¦¬åŒ¹'],
        'çƒ™è™Ÿ': ['Brand No.','Brand No','çƒ™è™Ÿ/ç·¨è™Ÿ','ç·¨è™Ÿ'],
        'è² ç£…': ['Handicap','Wt','Weight','è² ç£…(ç£…)'],
        'é¨å¸«': ['Jockey','é¨å¸«(å¯èƒ½è¶…ç£…)'],
        'æª”ä½': ['Draw','Gate','Barrier','æª”'],
        'ç·´é¦¬å¸«': ['Trainer','Trainers','ç·´è€…'],
        'è©•åˆ†': ['Rtg','Rating','è©•åˆ†(Rtg)'],
        'è©•åˆ†+/-': ['Rtg+/-','+/-','Rating+/-','è©•åˆ†è®Šå‹•'],
        'æ’ä½é«”é‡': ['Horse Wt.','Declared Wt.','é«”é‡','å®£å‘Šé«”é‡'],
        'æ’ä½é«”é‡+/-': ['Wt+/-','é«”é‡å¢æ¸›'],
        'é¦¬é½¡': ['Age'],
        'åˆ†é½¡è®“ç£…': ['WFA','Weight For Age','Allow','Allowance'],
        'æ€§åˆ¥': ['Sex','G'],
        'ä»Šå­£çé‡‘': ['Season Stakes','å­£å…§çé‡‘'],
        'å„ªå…ˆåƒè³½æ¬¡åº': ['Priority','å„ªå…ˆåº'],
        'ä¸Šè³½è·ä»Šæ—¥æ•¸': ['Days Since Last Run','DSLR','ä¸Šæ¬¡å‡ºè³½æ—¥æ•¸'],
        'é…å‚™': ['Gear','Equip'],
        'é¦¬ä¸»': ['Owner'],
        'çˆ¶ç³»': ['Sire'],
        'æ¯ç³»': ['Dam'],
        'é€²å£é¡åˆ¥': ['Import Cat.','Import','Import Category','ä¾†æ¸¯é¡åˆ¥'],
    }
    for i, h in enumerate(headers):
        clean = re.sub(r"\s+","",h).lower()
        for key, arr in aliases.items():
            for cand in [key] + arr:
                cc = re.sub(r"\s+","",cand).lower()
                if cc in clean or clean in cc:
                    idx.setdefault(key, i); break
    return idx

def _first_img_src(html_cell: str) -> str:
    m = re.search(r'<img[^>]+(?:data-src|src)="([^"]+)"', html_cell, re.I)
    if m:
        src = m.group(1)
        if src.startswith("http"): return src
        return BASE + ("" if src.startswith("/") else "/") + src
    m = re.search(r'<img[^>]+alt="([^"]+)"', html_cell, re.I)
    return strip_html(m.group(1)) if m else strip_html(html_cell)

def parse_table_generic(table_html: str) -> List[List[str]]:
    """å¼·åŒ–ç‰ˆå‡ºé¦¬è¡¨è§£æï¼ˆå®¹éŒ¯è¡¨é ­ã€æ¿¾å·¥å…·åˆ—/å°è¡¨é ­ã€è£œé¦¬å/é«”é‡è§£æï¼‰"""
    if not table_html:
        return []
    trs = re.findall(r"(?is)<tr[^>]*>([\s\S]*?)</tr>", table_html)
    if not trs:
        return []

    # 1) æ‰¾æœ€ä½³è¡¨é ­è¡Œ
    header_keywords = ['é¦¬å','è¿‘ç¸¾','é¨å¸«','ç·´é¦¬å¸«','æª”','æª”ä½','Draw','Rtg','Horse Wt.']
    best_i, best_score = 0, -1
    for i, tr in enumerate(trs[:8]):
        th_count = len(re.findall(r"(?i)<th\b", tr))
        raw = strip_html(tr)
        hit = sum(1 for kw in header_keywords if kw in raw)
        score = hit * 10 + th_count
        if score > best_score:
            best_score, best_i = score, i

    def extract_headers(tr_html: str):
        return [strip_html(x) for x in re.findall(r"(?is)<t[hd][^>]*>([\s\S]*?)</t[hd]>", tr_html)]

    header_tr = trs[best_i]
    headers = extract_headers(header_tr)

    # åˆ†çµ„è¡¨é ­ â†’ å¾€ä¸‹ä¸€è¡Œå°‹æ‰¾å…·é«”è‘‰å­æ¬„ä½
    leaf_needles = {'é¦¬å','æª”ä½','æ’ä½é«”é‡','è©•åˆ†','é¨å¸«','ç·´é¦¬å¸«',
                    'Horse','Draw','Horse Wt.','Jockey','Trainer','Rtg'}
    if not any(h for h in headers if any(n in h for n in leaf_needles)):
        for j in range(best_i + 1, min(best_i + 4, len(trs))):
            cand = extract_headers(trs[j])
            if any(h for h in cand if any(n in h for n in leaf_needles)):
                header_tr = trs[j]
                headers = cand
                best_i = j
                break

    idx = index_by_header(headers)
    have_header = bool(idx)

    # 2) ç”¨ç¬¬ä¸€æ¢æ•¸æ“šè¡Œè£œçŒœæ¬„ä½ï¼ˆæª”ä½/ç·´é¦¬å¸«/é¨å¸«ï¼‰
    for i, tr in enumerate(trs):
        if i == best_i:
            continue
        cells_html = re.findall(r"(?is)<t[dh][^>]*>([\s\S]*?)</t[dh]>", tr)
        cells_txt = [strip_html(x) for x in cells_html]
        if not cells_txt:
            continue
        joined = "|".join(cells_txt)
        # å°è¡¨é ­/å·¥å…·åˆ—
        if sum(w in joined for w in ['é¦¬å','è¿‘ç¸¾','é¨å¸«','ç·´é¦¬å¸«','Draw','Horse','Jockey','Trainer','Rtg','Horse Wt.']) >= 3:
            continue

        used = set(idx.values())
        for j, cell in enumerate(cells_txt):
            if j in used:
                continue
            if 'æª”ä½' not in idx and re.fullmatch(r"\d{1,2}", cell or "") and 1 <= int(cell) <= 20:
                idx.setdefault('æª”ä½', j); used.add(j); continue
            if 'ç·´é¦¬å¸«' not in idx and (('å¸«' in cell) or (re.search(r"[ä¸€-é¾¥]{2,}", cell) and not re.search(r"\d$", cell))):
                idx.setdefault('ç·´é¦¬å¸«', j); used.add(j); continue
            if 'é¨å¸«' not in idx and (re.search(r"[ä¸€-é¾¥]{2,}", cell) or re.search(r"^[A-Z]\.[A-Z][a-z]+", cell)):
                idx.setdefault('é¨å¸«', j); used.add(j); continue
        break

    use_guess = not have_header and not idx
    out: List[List[str]] = []

    # 3) é€è¡Œç”¢å‡º
    for i, tr in enumerate(trs):
        if i == best_i:
            continue
        cells_html = re.findall(r"(?is)<t[dh][^>]*>([\s\S]*?)</t[dh]>", tr)
        if not cells_html:
            continue
        cells_txt = [strip_html(x) for x in cells_html]

        raw_tr_text = strip_html(tr)
        # éæ¿¾éè³‡æ–™åˆ—
        if ("æˆ‘çš„æ’ä½è¡¨" in raw_tr_text) or ("è¨­å®šæˆ‘çš„æ’ä½è¡¨" in raw_tr_text) \
           or re.search(r'(?i)<input[^>]+type="checkbox"', tr):
            continue
        if any(w in raw_tr_text for w in ("ä¸‹è¼‰æ’ä½è³‡æ–™", "çµ±è¨ˆè³‡æ–™", "æ™¨æ“ç‰‡æ®µ", "å³æ™‚è³ ç‡", "è²¼å£«æŒ‡æ•¸", "å¤©æ°£åŠè·‘é“ç‹€æ³")):
            continue
        non_data = sum(1 for c in cells_txt if (c or "").strip() == "")
        if non_data >= max(2, len(cells_txt) - 2):
            continue
        if any("æˆ‘çš„æ’ä½è¡¨" in (c or "") for c in cells_txt[:2]):
            continue
        joined = "|".join(cells_txt)
        if sum(w in joined for w in ['é¦¬å','è¿‘ç¸¾','é¨å¸«','ç·´é¦¬å¸«','Draw','Horse','Jockey','Trainer','Rtg','Horse Wt.']) >= 3:
            continue

        if use_guess:
            guess = {
                'é¦¬åŒ¹ç·¨è™Ÿ': 0, '6æ¬¡è¿‘ç¸¾': 1, 'ç¶µè¡£': 2, 'é¦¬å': 3, 'çƒ™è™Ÿ': 4, 'è² ç£…': 5, 'é¨å¸«': 6,
                'æª”ä½': 7, 'ç·´é¦¬å¸«': 8, 'è©•åˆ†': 9, 'è©•åˆ†+/-': 10, 'æ’ä½é«”é‡': 11, 'æ’ä½é«”é‡+/-': 12,
                'é¦¬é½¡': 13, 'åˆ†é½¡è®“ç£…': 14, 'æ€§åˆ¥': 15, 'ä»Šå­£çé‡‘': 16, 'å„ªå…ˆåƒè³½æ¬¡åº': 17,
                'ä¸Šè³½è·ä»Šæ—¥æ•¸': 18, 'é…å‚™': 19, 'é¦¬ä¸»': 20, 'çˆ¶ç³»': 21, 'æ¯ç³»': 22, 'é€²å£é¡åˆ¥': 23
            }
            td_count = len(cells_html)
            idx_guess = {k: (v if v < td_count else -1) for k, v in guess.items()}

            def get_guess(key: str) -> str:
                j = idx_guess.get(key, -1)
                if j < 0 or j >= len(cells_html):
                    return ""
                return _first_img_src(cells_html[j]) if key == 'ç¶µè¡£' else cells_txt[j]

            out.append([get_guess(k) for k in WANTED_COLUMNS])
            continue

        def get_by_header(key: str) -> str:
            j = idx.get(key, -1)
            if j < 0 or j >= len(cells_html):
                return ""
            cell_html = cells_html[j]
            cell_txt = cells_txt[j]
            if key == 'ç¶µè¡£':
                return _first_img_src(cell_html)
            if key == 'é¨å¸«':
                return re.sub(r"\((?:[-+]?\d+)\)", "", cell_txt).strip()
            if key == 'é¦¬å':
                m = re.search(r'<a[^>]+href="[^"]*Horse[^"]*"[^>]*>([\s\S]*?)</a>', cell_html, re.I)
                if m:
                    name = strip_html(m.group(1))
                    if name:
                        return name
                if (re.fullmatch(r"\d+", cell_txt or "") or len(cell_txt) <= 2):
                    mm = re.search(r'<a[^>]+href="[^"]*Horse[^"]*"[^>]*>([\s\S]*?)</a>', tr, re.I)
                    if mm:
                        alt = strip_html(mm.group(1))
                        if alt:
                            return alt
                return cell_txt
            if key in ('æ’ä½é«”é‡', 'æ’ä½é«”é‡+/-'):
                m = re.search(r'(\d{2,4})\s*(?:\(\s*([+-]?\d+)\s*\))?', strip_html(cell_html)) or \
                    re.search(r'(\d{2,4})\s*(?:\(\s*([+-]?\d+)\s*\))?', cell_txt)
                if m:
                    wt = m.group(1) or ''
                    dlt = m.group(2) or ''
                    return wt if key == 'æ’ä½é«”é‡' else dlt
                return cell_txt
            return cell_txt

        out.append([get_by_header(k) for k in WANTED_COLUMNS])

    return out

def parse_reserves_from_chinese(compact_html: str) -> List[List[str]]:
    blk = re.search(r"å¾Œå‚™é¦¬åŒ¹[\s\S]*?</table>", compact_html)
    if not blk: return []
    row_re = re.compile(r"(?is)<tr[^>]*>([\s\S]*?)</tr>")
    cell_re = re.compile(r"(?is)<t[dh][^>]*>([\s\S]*?)</t[dh]>")
    out=[]; first=True
    for m in row_re.finditer(blk.group(0)):
        cells = [strip_html(c) for c in cell_re.findall(m.group(1))]
        if first: first=False; continue
        if not cells: continue
        row = [(cells[i] if i < len(cells) else "") for i in range(10)]
        out.append(row)
    return out

# ---------- é–‹è³½æ™‚é–“ + è³½äº‹å±¤ ----------
def extract_off_time_local(html: str) -> str:
    if not html:
        return ""
    for tag in ("h1", "h2"):
        m = re.search(fr"<{tag}[^>]*>([\s\S]*?)</{tag}>", html, re.I)
        if m:
            t = strip_html(m.group(1))
            m2 = TIME_RE.search(t)
            if m2:
                return m2.group(1)
    cut = re.split(r"è¨­å®šæˆ‘çš„æ’ä½è¡¨|My Race Card", html, flags=re.I)[0]
    t = strip_html(cut)
    m3 = TIME_RE.search(t)
    return m3.group(1) if m3 else ""

def compose_off_times(meeting_date_iso: str, hhmm: str) -> dict:
    if not (meeting_date_iso and hhmm):
        return {'off_time_local': '', 'off_time_hkt': '', 'off_time_utc': ''}
    dt_hkt = _dt.datetime.strptime(f"{meeting_date_iso} {hhmm}", "%Y-%m-%d %H:%M").replace(
        tzinfo=ZoneInfo("Asia/Hong_Kong")
    )
    return {
        'off_time_local': hhmm,
        'off_time_hkt': dt_hkt.isoformat(timespec="seconds"),
        'off_time_utc': dt_hkt.astimezone(ZoneInfo("UTC")).isoformat(timespec="seconds").replace("+00:00","Z")
    }

def parse_race_meta(html: str) -> Dict[str, Any]:
    m = re.search(r"<h1[^>]*>([\s\S]*?)</h1>", html, re.I)
    title = strip_html(m.group(1)) if m else ""
    return {"title": title}

def extract_race_details(html_zh: str, html_en: str, meeting_date_iso: str, venue_code: str) -> Dict[str, Any]:
    soup_zh = BeautifulSoup(html_zh, "lxml")
    text_zh = soup_zh.get_text(" ", strip=True)

    # race name zhï¼šh1 çš„ã€Œç¬¬ n å ´ - åç¨±ã€å³é‚Šéƒ¨ä»½
    h1 = soup_zh.find("h1")
    race_name_zh = ""
    if h1:
        t = strip_html(str(h1))
        race_name_zh = re.sub(r"^ç¬¬\s*\d+\s*å ´\s*[-â€“â€”]\s*", "", strip_html(t))

    # race name enï¼ˆè‹±é  h1ï¼‰
    race_name_en = ""
    if html_en:
        soup_en = BeautifulSoup(html_en, "lxml")
        h1e = soup_en.find("h1")
        if h1e:
            tt = strip_html(str(h1e))
            race_name_en = re.sub(r"^Race\s*\d+\s*[-â€“â€”]\s*", "", strip_html(tt))

    # surface / course line / distance
    surface = ""
    for w in SURF_WORDS:
        if w in text_zh:
            surface = "AWT" if ("AWT" in w or "å…¨å¤©" in w) else "è‰åœ°"
            break

    m_line = re.search(r"[\"â€œ]([ABC](?:\+\d)?)[\"â€]\s*è³½é“", text_zh)
    course_line = m_line.group(1) if m_line else ""

    m_dist = re.search(r"(\d{3,4})\s*ç±³", text_zh)
    distance_m = int(m_dist.group(1)) if m_dist else None

    # goingï¼ˆæœ‰æ™‚åœ¨å…¶ä»–å€å¡Šï¼‰
    going = ""
    for w in GOING_WORDS:
        if w in text_zh:
            going = w
            break

    # class / handicap
    class_text = ""
    m_cls = re.search(r"(ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ç­|Class\s*\d+|Group\s*\d+)", text_zh, re.I)
    if m_cls:
        class_text = m_cls.group(1)
    handicap = "è®“è³½" if ("è®“è³½" in race_name_zh or "Handicap" in race_name_en) else ""

    # é–‹è³½æ™‚é–“ï¼ˆå·²åœ¨å¤–é¢æŠ½ localï¼Œå†åˆæˆï¼‰
    off_local = extract_off_time_local(html_zh)
    off = compose_off_times(meeting_date_iso, off_local)

    return {
        "race_name_zh": race_name_zh,
        "race_name_en": race_name_en,
        "race_time_local": off["off_time_local"],
        "race_time_hkt": off["off_time_hkt"],
        "race_time_utc": off["off_time_utc"],
        "distance_m": distance_m,
        "surface": surface,           # è‰åœ° / AWT
        "course_line": course_line,   # A / B / C / C+3 ...
        "going": going,
        "class_text": class_text,
        "handicap": handicap,
        "venue_code": venue_code      # ST / HV
    }

# ---------- æŠŠå–®è¡Œå‡ºé¦¬è³‡æ–™è½‰ dictï¼ˆæ–¹ä¾¿å…¥ DBï¼‰ ----------
def row_to_entry(row: List[str]) -> Dict[str, Any]:
    m = { WANTED_COLUMNS[i]: (row[i] if i < len(row) else "") for i in range(len(WANTED_COLUMNS)) }
    def to_int(s):
        try:
            return int(re.sub(r"[^\d-]+","", s))
        except:
            return None

    draw_val = m.get("æª”ä½") or ""
    trainer_val = m.get("ç·´é¦¬å¸«") or ""
    name_val = m.get("é¦¬å") or ""

    # åç¨± sanityï¼šåªéæ¿¾ã€Œæˆ‘çš„æ’ä½è¡¨ã€æˆ–ç´”æ•¸å­—ï¼›å…©å€‹å­—çš„æ­£å¸¸é¦¬åä¿ç•™
    norm = (name_val or "").replace(" ", "")
    if ("æˆ‘çš„æ’ä½è¡¨" in norm) or re.fullmatch(r"\d+", norm or ""):
        name_val = ""

    # trainer æ˜¯ 1~20 çš„ç´”æ•¸å­—è€Œ draw ç©º â†’ è¦–ç‚º draw
    if (not draw_val) and re.fullmatch(r"\d{1,2}", trainer_val or "") and 1 <= int(trainer_val) <= 20:
        draw_val, trainer_val = trainer_val, ""
    # draw æœ‰ä¸­æ–‡å­—/è‹±æ–‡å­—æ¨£è€Œ trainer ç©º â†’ äº’æ›
    if (not trainer_val) and re.search(r"[A-Za-zä¸€-é¾¥]", draw_val or "") and not re.fullmatch(r"\d{1,2}", draw_val or ""):
        draw_val, trainer_val = "", draw_val

    return {
        "horse_no": to_int(m.get("é¦¬åŒ¹ç·¨è™Ÿ") or ""),
        "last6": m.get("6æ¬¡è¿‘ç¸¾") or "",
        "silks": m.get("ç¶µè¡£") or "",
        "horse_name_zh": name_val,
        "brand": m.get("çƒ™è™Ÿ") or "",
        "weight_lb": to_int(m.get("è² ç£…") or ""),
        "jockey_zh": m.get("é¨å¸«") or "",
        "draw": to_int(draw_val or ""),
        "trainer_zh": trainer_val,
        "rating": to_int(m.get("è©•åˆ†") or ""),
        "rating_pm": m.get("è©•åˆ†+/-") or "",
        "declared_wt": to_int(m.get("æ’ä½é«”é‡") or ""),
        "declared_wt_pm": m.get("æ’ä½é«”é‡+/-") or "",
        "age": to_int(m.get("é¦¬é½¡") or ""),
        "wfa": m.get("åˆ†é½¡è®“ç£…") or "",
        "sex": m.get("æ€§åˆ¥") or "",
        "season_stakes": m.get("ä»Šå­£çé‡‘") or "",
        "priority": m.get("å„ªå…ˆåƒè³½æ¬¡åº") or "",
        "days_since": m.get("ä¸Šè³½è·ä»Šæ—¥æ•¸") or "",
        "gear": m.get("é…å‚™") or "",
        "owner": m.get("é¦¬ä¸»") or "",
        "sire": m.get("çˆ¶ç³»") or "",
        "dam": m.get("æ¯ç³»") or "",
        "import_cat": m.get("é€²å£é¡åˆ¥") or "",
    }

# ---------- è‡ªè¨‚æ¬„ä½ï¼ˆå‹¾é¸ï¼‰ ----------
DESIRED_LABELS = ["çˆ¶ç³»", "æ¯ç³»", "é€²å£é¡åˆ¥"]

def _find_label_checkbox(driver, label_text):
    try:
        lab = driver.find_element(By.XPATH, f"//label[contains(normalize-space(.), '{label_text}')]")
        try:
            cid = lab.get_attribute("for")
            cb = driver.find_element(By.ID, cid) if cid else lab.find_element(By.XPATH, ".//input[@type='checkbox']")
            return cb
        except Exception:
            pass
    except Exception:
        pass
    try:
        cb = driver.find_element(
            By.XPATH,
            f"//td[.//text()[contains(., '{label_text}')]]//input[@type='checkbox']"
        )
        return cb
    except Exception:
        return None

def ensure_racecard_columns(driver, labels=DESIRED_LABELS, timeout=12):
    try:
        anchor = driver.find_element(By.XPATH, "//*[contains(normalize-space(.), 'è¨­å®šæˆ‘çš„æ’ä½è¡¨')]")
        driver.execute_script("arguments[0].scrollIntoView({block:'center'});", anchor)
    except Exception:
        pass
    try:
        for txt in ["æŒ‰æ­¤é—œé–‰", "æŒ‰æ­¤é–‹å•Ÿ", "æŒ‰æ­¤é—œé–‰ ", "æŒ‰æ­¤é–‹å•Ÿ "]:
            elems = driver.find_elements(By.XPATH, f"//a[normalize-space()='{txt}']")
            if elems:
                driver.execute_script("arguments[0].scrollIntoView({block:'center'});", elems[0])
                elems[0].click()
                break
    except Exception:
        pass
    for name in labels:
        cb = _find_label_checkbox(driver, name)
        if not cb:
            continue
        driver.execute_script("arguments[0].scrollIntoView({block:'center'});", cb)
        if not cb.is_selected():
            try:
                cb.click()
            except Exception:
                driver.execute_script("arguments[0].checked = true;", cb)
    try:
        btns = driver.find_elements(By.XPATH, "//*[contains(normalize-space(.), 'è¨­å®šæˆ‘çš„æ’ä½è¡¨')]/following::a[normalize-space()='é‡æ–°æ•´ç†'][1]")
        if not btns:
            btns = driver.find_elements(By.XPATH, "//a[normalize-space()='é‡æ–°æ•´ç†']")
        if btns:
            driver.execute_script("arguments[0].scrollIntoView({block:'center'});", btns[0])
            btns[0].click()
        else:
            b2 = driver.find_element(By.XPATH, "//button[normalize-space()='é‡æ–°æ•´ç†']")
            driver.execute_script("arguments[0].scrollIntoView({block:'center'});", b2)
            b2.click()
    except Exception:
        pass
    try:
        WebDriverWait(driver, timeout).until(
            EC.presence_of_element_located((
                By.XPATH,
                "//table//th[contains(., 'çˆ¶ç³»')] | //table//th[contains(., 'æ¯ç³»')] | //table//th[contains(., 'é€²å£é¡åˆ¥')]"
            ))
        )
    except Exception:
        WebDriverWait(driver, 3).until(
            lambda d: "çˆ¶ç³»" in d.page_source or "æ¯ç³»" in d.page_source or "é€²å£é¡åˆ¥" in d.page_source
        )

# ---------- Autodetect è³½æ—¥/å ´åœ° ----------
def autodetect_meeting(driver) -> Tuple[str, str]:
    driver.get(DEFAULT_RC)
    WebDriverWait(driver, 12).until(EC.presence_of_element_located((By.TAG_NAME, "body")))
    time.sleep(0.5)
    html = driver.page_source

    for m in re.finditer(r'href="[^"]*RaceCard\.aspx\?([^"]+)"', html, re.I):
        qs = m.group(1)
        mdate = re.search(r'(?:RaceDate|RDate|racedate)=([^&"]+)', qs, re.I)
        mcourse = re.search(r'Racecourse=(ST|HV)', qs, re.I)
        if mdate and mcourse:
            date_raw = mdate.group(1)
            course = mcourse.group(1).upper()
            return date_raw.replace("-", "/"), course

    soup = BeautifulSoup(html, "lxml")
    text = soup.get_text(" ", strip=True)
    date_str = None
    m = re.search(r"(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥", text)
    if m:
        y, mo, d = m.groups()
        date_str = f"{int(y):04d}/{int(mo):02d}/{int(d):02d}"
    course = None
    if "è·‘é¦¬åœ°" in text: course = "HV"
    if "æ²™ç”°" in text:   course = course or "ST"
    if not date_str or not course:
        raise RuntimeError("ç„¡æ³•è‡ªå‹•åµæ¸¬ RaceDate / Racecourseã€‚")
    return date_str, course

# ---------- å–®å ´æŠ“å– ----------
def fetch_one_race_html(driver, date_str: str, race_no: int, course: str, wait_sec=15) -> str:
    def open_and_prepare(url: str) -> str:
        driver.get(url)
        try:
            WebDriverWait(driver, wait_sec).until(lambda d: 'table' in d.page_source.lower())
        except Exception:
            pass
        try:
            ensure_racecard_columns(driver, labels=DESIRED_LABELS)
        except Exception:
            pass
        return driver.page_source

    c = "HV" if str(course).upper()=="HV" else "ST"
    last_html = ""
    for p in ZH_PATHS:
        for k in ["RaceDate","RDate","racedate"]:
            url = f"{BASE}{p}?{k}={date_str}&RaceNo={race_no}&Racecourse={c}"
            html = open_and_prepare(url)
            last_html = html or last_html
            if has_starter_table(html):
                return html
    return last_html

def fetch_one_race_html_en(driver, date_str: str, race_no: int, course: str, wait_sec=8) -> str:
    c = "HV" if str(course).upper()=="HV" else "ST"
    for p in EN_PATHS:
        for k in ["RaceDate","RDate","racedate"]:
            url = f"{BASE}{p}?{k}={date_str}&RaceNo={race_no}&Racecourse={c}"
            driver.get(url)
            try:
                WebDriverWait(driver, wait_sec).until(lambda d: 'table' in d.page_source.lower())
            except Exception:
                pass
            return driver.page_source
    return ""

# ---------- æœƒæœŸ ----------
def crawl_meeting(auto_date: Optional[str],
                  auto_course: Optional[str],
                  max_races: Optional[int],
                  headful: bool=False,
                  delay_between=0.35) -> Dict[str, Any]:
    opts = Options()
    if not headful:
        opts.add_argument("--headless=new")
    opts.add_argument("--disable-gpu")
    opts.add_argument("--no-sandbox")
    opts.add_argument("--lang=zh-HK")
    opts.add_argument("--window-size=1280,2200")
    opts.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120 Safari/537.36")

    with webdriver.Chrome(options=opts) as driver:
        driver.get(f"{BASE}/")
        WebDriverWait(driver, 6).until(EC.presence_of_element_located((By.TAG_NAME, "body")))
        time.sleep(0.3)

        # è‡ªå‹•åµæ¸¬ï¼ˆå¦‚ç„¡å‚³å…¥ï¼‰
        if not auto_date or not auto_course:
            date_str, course = autodetect_meeting(driver)
        else:
            date_str = auto_date.replace("-", "/")
            course = auto_course.upper()

        meeting = {
            "date": date_str.replace("/", "-"),
            "course": "æ²™ç”°" if course == "ST" else ("è·‘é¦¬åœ°" if course == "HV" else ""),
            "venue_code": course,
            "races": []
        }

        # å ´æ•¸è‡ªå‹•ï¼šå¦‚æ²’æŒ‡å®š max_racesï¼Œå°±å˜—è©¦æœ€å¤š 20 å ´ï¼›é€£çºŒ 2 å ´æµå””åˆ°å°±æ”¶æ‰‹
        hard_cap = max_races if (max_races and max_races > 0) else 20
        consecutive_miss = 0
        last_ok_html = ""
        any_found = False

        for rn in range(1, hard_cap + 1):
            html = fetch_one_race_html(driver, date_str, rn, course)
            if not (html and has_starter_table(html)):
                consecutive_miss += 1
                if consecutive_miss >= 2:
                    break
                else:
                    continue

            # æœ‰è¡¨ï¼šæ¸…é›¶ miss è¨ˆæ•¸
            consecutive_miss = 0
            any_found = True
            last_ok_html = html

            # è‹±æ–‡é ï¼ˆè£œè‹±æ–‡è³½åï¼‰
            html_en = fetch_one_race_html_en(driver, date_str, rn, course)

            compact = compact_html(html)
            meta_title = parse_race_meta(html)
            rows_raw = parse_table_generic(pick_starter_table(compact))
            reserves_raw = parse_reserves_from_chinese(compact)

            # è³½äº‹å±¤
            race_meta = extract_race_details(html, html_en, meeting["date"], course)

            # é€è¡Œè½‰ dictï¼Œç„¡é¦¬åçš„è·³éï¼›äº¦æœƒéæ¿¾ã€Œæˆ‘çš„æ’ä½è¡¨ã€å‡è¡Œ
            entries = []
            for r in rows_raw:
                e = row_to_entry(r)
                name = (e.get("horse_name_zh") or "").strip()
                if not re.search(r"[A-Za-zä¸€-é¾¥]", name):
                    continue
                if "æˆ‘çš„æ’ä½è¡¨" in name:
                    continue
                entries.append(e)

            reserves = []
            for r in reserves_raw or []:
                e = row_to_entry(r)
                name = (e.get("horse_name_zh") or "").strip()
                if not re.search(r"[A-Za-zä¸€-é¾¥]", name):
                    continue
                reserves.append(e)

            # å¦‚æœå‘¢å ´é€£ä¸€åŒ¹æœ‰æ•ˆé¦¬éƒ½ç„¡ï¼Œå°±ç•¶ä½œç©ºå ´ï¼Œå””åŠ å…¥
            if not entries and not reserves:
                continue

            meeting["races"].append({
                "race_no": rn,
                "title": meta_title.get("title", ""),
                "meta": race_meta,
                "entries": entries,
                "reserves": reserves
            })

            time.sleep(delay_between)

        # ç”¨æœ€å¾ŒæˆåŠŸé ä¿®æ­£æ—¥æœŸ/å ´åœ°ä¸­æ–‡
        if any_found and last_ok_html:
            soup = BeautifulSoup(last_ok_html, "lxml")
            text = soup.get_text(" ", strip=True)
            m = re.search(r"(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥", text)
            if m:
                y, mo, d = m.groups()
                meeting["date"] = f"{int(y):04d}-{int(mo):02d}-{int(d):02d}"
            if "è·‘é¦¬åœ°" in text:
                meeting["course"] = "è·‘é¦¬åœ°"
            if "æ²™ç”°" in text:
                meeting["course"] = meeting["course"] or "æ²™ç”°"

        return meeting

# ---------- CSV ----------
def write_csv(meeting: Dict[str,Any], races_csv="races.csv", entries_csv="entries.csv"):
    # races
    with open(races_csv, "w", newline="", encoding="utf-8-sig") as f:
        w = csv.writer(f)
        w.writerow([
            "date","venue_code","course","race_no",
            "race_name_zh","race_name_en","race_time_local","race_time_hkt","race_time_utc",
            "distance_m","surface","course_line","going","class_text","handicap","title"
        ])
        for r in meeting.get("races",[]):
            m = r.get("meta", {})
            w.writerow([
                meeting.get("date",""),
                meeting.get("venue_code",""),
                meeting.get("course",""),
                r.get("race_no",""),
                m.get("race_name_zh",""), m.get("race_name_en",""),
                m.get("race_time_local",""), m.get("race_time_hkt",""), m.get("race_time_utc",""),
                m.get("distance_m",""), m.get("surface",""), m.get("course_line",""), m.get("going",""),
                m.get("class_text",""), m.get("handicap",""), r.get("title","")
            ])
    # entries
    with open(entries_csv, "w", newline="", encoding="utf-8-sig") as f:
        w = csv.writer(f)
        cols = [
            "date","venue_code","race_no","is_reserve",
            "horse_no","horse_name_zh","brand","draw","jockey_zh","trainer_zh",
            "rating","rating_pm","weight_lb","declared_wt","declared_wt_pm",
            "age","sex","wfa","gear","last6","owner","sire","dam","import_cat"
        ]
        w.writerow(cols)
        for r in meeting.get("races",[]):
            for e in r.get("entries",[]):
                w.writerow([
                    meeting.get("date",""), meeting.get("venue_code",""), r["race_no"], 0,
                    e.get("horse_no",""), e.get("horse_name_zh",""), e.get("brand",""),
                    e.get("draw",""), e.get("jockey_zh",""), e.get("trainer_zh",""),
                    e.get("rating",""), e.get("rating_pm",""), e.get("weight_lb",""),
                    e.get("declared_wt",""), e.get("declared_wt_pm",""),
                    e.get("age",""), e.get("sex",""), e.get("wfa",""),
                    e.get("gear",""), e.get("last6",""), e.get("owner",""),
                    e.get("sire",""), e.get("dam",""), e.get("import_cat","")
                ])
            for e in r.get("reserves",[]):
                w.writerow([
                    meeting.get("date",""), meeting.get("venue_code",""), r["race_no"], 1,
                    e.get("horse_no",""), e.get("horse_name_zh",""), e.get("brand",""),
                    e.get("draw",""), e.get("jockey_zh",""), e.get("trainer_zh",""),
                    e.get("rating",""), e.get("rating_pm",""), e.get("weight_lb",""),
                    e.get("declared_wt",""), e.get("declared_wt_pm",""),
                    e.get("age",""), e.get("sex",""), e.get("wfa",""),
                    e.get("gear",""), e.get("last6",""), e.get("owner",""),
                    e.get("sire",""), e.get("dam",""), e.get("import_cat","")
                ])

# ---------- MySQL ä¿å­˜ ----------
import pymysql
from contextlib import contextmanager

@contextmanager
def _mysql_conn(cfg):
    conn = pymysql.connect(
        host=cfg["host"],
        port=int(cfg.get("port", 3306)),
        user=cfg["user"],
        password=cfg.get("password", ""),
        database=cfg["db"],
        charset="utf8mb4",
        autocommit=False,
        cursorclass=pymysql.cursors.DictCursor,
    )
    try:
        yield conn
        conn.commit()
    except Exception:
        conn.rollback()
        raise
    finally:
        conn.close()

def _safe_join(parts, sep=" / "):
    vals = [str(p).strip() for p in parts if p]
    return sep.join(vals) if vals else None

def load_mysql_cfg_from_env() -> dict:
    """
    ç”±ç’°å¢ƒè®Šæ•¸è®€ MySQL è¨­å®šï¼š
      DB_HOST / DB_PORT / DB_USER / DB_PASS / DB_NAME
    - æœ¬åœ°ï¼šç”¨ .env + OS ç’°å¢ƒè®Šæ•¸
    - Renderï¼šç”¨ Render Dashboard è¨­å˜…ç’°å¢ƒè®Šæ•¸
    """
    return {
        "host": os.getenv("DB_HOST", "127.0.0.1"),
        "port": int(os.getenv("DB_PORT", "3306")),
        "user": os.getenv("DB_USER", "root"),
        "password": os.getenv("DB_PASS", ""),
        "db": os.getenv("DB_NAME", "hkjc_db"),
    }


def save_to_mysql(meeting: dict, mysql_cfg: dict):
    """
    å°‡ meeting çµæ§‹å¯«å…¥ï¼š
      - racecard_races (ä¸€å ´ä¸€è¡Œ)
      - racecard_entries (æ¯åŒ¹ä¸€è¡Œ)
    ä»¥ (race_date, race_no) åŠ (race_date, race_no, horse_no) ä½œå”¯ä¸€éµ UPSERTã€‚
    """
    race_sql = """
    INSERT INTO racecard_races (
        race_date, race_no, race_time, race_name_zh, race_name_en,
        distance_m, course, going, class_text, handicap,
        draw_date, venue_code
    ) VALUES (
        %(race_date)s, %(race_no)s, %(race_time)s, %(race_name_zh)s, %(race_name_en)s,
        %(distance_m)s, %(course)s, %(going)s, %(class_text)s, %(handicap)s,
        %(draw_date)s, %(venue_code)s
    )
    ON DUPLICATE KEY UPDATE
        race_time=VALUES(race_time),
        race_name_zh=VALUES(race_name_zh),
        race_name_en=VALUES(race_name_en),
        distance_m=VALUES(distance_m),
        course=VALUES(course),
        going=VALUES(going),
        class_text=VALUES(class_text),
        handicap=VALUES(handicap),
        draw_date=VALUES(draw_date),
        venue_code=VALUES(venue_code);
    """

    entry_sql = """
    INSERT INTO racecard_entries (
        race_date, race_no, horse_no,
        horse_name_zh, horse_name_en,
        horse_code, draw,
        jockey_zh, trainer_zh,
        rating, rating_pm,
        weight_lb, declared_wt, declared_wt_pm,
        age, sex, wfa,
        season_stakes, priority, days_since,
        owner, sire, dam, import_cat,
        silks, brand, gear, last6,
        scratched
    ) VALUES (
        %(race_date)s, %(race_no)s, %(horse_no)s,
        %(horse_name_zh)s, %(horse_name_en)s,
        %(horse_code)s, %(draw)s,
        %(jockey_zh)s, %(trainer_zh)s,
        %(rating)s, %(rating_pm)s,
        %(weight_lb)s, %(declared_wt)s, %(declared_wt_pm)s,
        %(age)s, %(sex)s, %(wfa)s,
        %(season_stakes)s, %(priority)s, %(days_since)s,
        %(owner)s, %(sire)s, %(dam)s, %(import_cat)s,
        %(silks)s, %(brand)s, %(gear)s, %(last6)s,
        %(scratched)s
    )
    ON DUPLICATE KEY UPDATE
        horse_name_zh  = VALUES(horse_name_zh),
        horse_name_en  = VALUES(horse_name_en),
        horse_code     = VALUES(horse_code),
        draw           = VALUES(draw),
        jockey_zh      = VALUES(jockey_zh),
        trainer_zh     = VALUES(trainer_zh),
        rating         = VALUES(rating),
        rating_pm      = VALUES(rating_pm),
        weight_lb      = VALUES(weight_lb),
        declared_wt    = VALUES(declared_wt),
        declared_wt_pm = VALUES(declared_wt_pm),
        age            = VALUES(age),
        sex            = VALUES(sex),
        wfa            = VALUES(wfa),
        season_stakes  = VALUES(season_stakes),
        priority       = VALUES(priority),
        days_since     = VALUES(days_since),
        owner          = VALUES(owner),
        sire           = VALUES(sire),
        dam            = VALUES(dam),
        import_cat     = VALUES(import_cat),
        silks          = VALUES(silks),
        brand          = VALUES(brand),
        gear           = VALUES(gear),
        last6          = VALUES(last6),
        scratched      = VALUES(scratched);
    """

    race_date = meeting.get("date")
    venue_code = meeting.get("venue_code")

    race_rows = []
    entry_rows = []

    for r in meeting.get("races", []):
        meta = r.get("meta", {}) or {}
        race_rows.append({
            "race_date": race_date,
            "race_no": r.get("race_no"),
            "race_time": (meta.get("race_time_local") or None),  # 'HH:MM' â†’ TIME
            "race_name_zh": meta.get("race_name_zh") or "",
            "race_name_en": meta.get("race_name_en") or "",
            "distance_m": meta.get("distance_m"),
            "course": _safe_join([meta.get("surface"), meta.get("course_line")]),  # ä¾‹å¦‚ã€Œè‰åœ° / Bã€
            "going": meta.get("going") or "",
            "class_text": meta.get("class_text") or "",
            "handicap": meta.get("handicap") or "",
            "draw_date": None,
            "venue_code": venue_code or None,
        })

        for e in (r.get("entries") or []):
            if not e.get("horse_no"):
                continue

            entry_rows.append({
                "race_date": race_date,
                "race_no": r.get("race_no"),
                "horse_no": e.get("horse_no"),

                "horse_name_zh": e.get("horse_name_zh") or "",
                "horse_name_en": "",  # æš«æ™‚å†‡è‹±æ–‡å

                # ä½ ä¾å®¶ JSON å…¥é¢ horse_code å†‡çœŸ codeï¼Œåªå¾— brand noï¼Œæ‰€ä»¥å…ˆæ²¿ç”¨ brand åš horse_code
                "horse_code": e.get("brand") or None,

                "draw": e.get("draw"),
                "jockey_zh": e.get("jockey_zh") or "",
                "trainer_zh": e.get("trainer_zh") or "",

                "rating": e.get("rating"),
                "rating_pm": e.get("rating_pm") or "",

                "weight_lb": e.get("weight_lb"),
                "declared_wt": e.get("declared_wt"),
                "declared_wt_pm": e.get("declared_wt_pm") or "",

                "age": e.get("age"),
                "sex": e.get("sex") or "",
                "wfa": e.get("wfa") or "",

                "season_stakes": e.get("season_stakes") or "",
                "priority": e.get("priority") or "",
                "days_since": e.get("days_since") or "",

                "owner": e.get("owner") or "",
                "sire": e.get("sire") or "",
                "dam": e.get("dam") or "",
                "import_cat": e.get("import_cat") or "",

                "silks": e.get("silks") or "",
                "brand": e.get("brand") or "",
                "gear": e.get("gear") or "",
                "last6": e.get("last6") or "",

                "scratched": 0,
            })


    if not race_rows and not entry_rows:
        return 0, 0

    with _mysql_conn(mysql_cfg) as conn:
        with conn.cursor() as cur:
            if race_rows:
                cur.executemany(race_sql, race_rows)
            if entry_rows:
                cur.executemany(entry_sql, entry_rows)

    return len(race_rows), len(entry_rows)


# ---------- çµ¦ scheduler ç”¨çš„å°è£å‡½å¼ ----------
def fetch_and_store_racecard(
    race_date: str,
    venue_code: str,
    draw_date: Optional[str] = None,
    mysql_cfg: Optional[dict] = None,
):
    """
    æ¯” hkjc_racecard_scheduler.py ç”¨ï¼š
      race_date  : 'YYYY-MM-DD'
      venue_code : 'ST' / 'HV'
      draw_date  : 'YYYY-MM-DD'ï¼ˆæ’ä½æ—¥ï¼Œä¸å¡«å°±ç”¨ race_dateï¼‰
    DB:
      å¦‚ mysql_cfg ç‚º None â†’ è‡ªå‹•ç”¨ç’°å¢ƒè®Šæ•¸ï¼ˆ.env / Renderï¼‰
    """
    if mysql_cfg is None:
        mysql_cfg = load_mysql_cfg_from_env()

    # çˆ¬å…¨æ—¥æ’ä½
    meeting = crawl_meeting(race_date, venue_code, max_races=None, headful=False)

    # è£œ draw_date / venue_code è³‡è¨Šï¼ˆå¯é¸ï¼‰
    for r in meeting.get("races", []):
        meta = r.get("meta") or {}
        meta.setdefault("draw_date", draw_date or race_date)
        meta.setdefault("venue_code", venue_code)
        r["meta"] = meta

    races_cnt, entries_cnt = save_to_mysql(meeting, mysql_cfg)
    return races_cnt, entries_cnt


# ---------- CLI ----------
def main():
    ap = argparse.ArgumentParser(description="HKJC RaceCard (Selenium) â€” è³‡æ–™æ“´å……ç‰ˆ")
    ap.add_argument("--date", help="YYYY-MM-DDï¼›ä¸å¡«å‰‡è‡ªå‹•åµæ¸¬")
    ap.add_argument("--course", choices=["ST","HV"], help="ST/HVï¼›ä¸å¡«å‰‡è‡ªå‹•åµæ¸¬")
    ap.add_argument("--max-races", type=int, default=0, help="æœ€å¤šè©¦å¹¾å¤šå ´ï¼›0=è‡ªå‹•(æœ€å¤š20ä¸¦é€£çºŒ2å ´ç„¡å°±åœ)")
    ap.add_argument("--headful", action="store_true")
    ap.add_argument("--csv-out", action="store_true")

    # MySQL
    ap.add_argument("--mysql", action="store_true", help="å¯«å…¥ MySQL")
    ap.add_argument("--mysql-host", default="127.0.0.1")
    ap.add_argument("--mysql-port", type=int, default=3306)
    ap.add_argument("--mysql-user", default="root")
    ap.add_argument("--mysql-pass", default="")
    ap.add_argument("--mysql-db",   default="hkjc")

    args = ap.parse_args()

    meeting = crawl_meeting(args.date, args.course, args.max_races or None, headful=args.headful)
    print("âœ… çˆ¬å–å®Œæˆ")
    print(json.dumps(meeting, ensure_ascii=False, indent=2))

    if args.csv_out:
        write_csv(meeting)
        print("ğŸ“„ å·²è¼¸å‡º races.csv / entries.csv")

    if args.mysql:
        # ä¸€å¾‹ç”¨ç’°å¢ƒè®Šæ•¸ï¼ˆ.env / Render Environmentï¼‰
        cfg = load_mysql_cfg_from_env()
        races_cnt, entries_cnt = save_to_mysql(meeting, cfg)
        print(f"âœ… æˆåŠŸå¯«å…¥ MySQL â†’ è³½äº‹ {races_cnt} å ´ï¼ŒåŒ¹é¦¬ {entries_cnt} è¡Œ")


if __name__ == "__main__":
    main()
